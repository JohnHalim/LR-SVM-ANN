###########maer##########
import glob
import pandas as pd  # as means that we use pandas library short form  as pd
import cv2
import numpy as np
from matplotlib import pyplot as plt # matplotlib is big library, we are just calling pyplot function 
                                    # for showing images
from skimage.feature import hog #We are calling only hog  

from sklearn.decomposition import PCA # Calling the PCA funtion from sklearn
from sklearn.svm import SVC # # Calling the SVM function from sklearn
#from sklearn.externals import joblib # Calling the joblib function from sklearn, use for model saving 
                                     # and loading.
import matplotlib
import skimage 
import sklearn

Training_Images_Directory='/content/drive/MyDrive/Training 2' #training dataset directory.

csv_files_training=glob.glob(Training_Images_Directory+'/**/*.csv',recursive=True) # recursive true means it will check 
                                                                          # folder inside the folder as well.
main_Training=pd.read_csv(csv_files_training[0],sep=';') # reading first csv and assining it main csv.
for i in range(1,len(csv_files_training)): # for loop iteration from 1 to number of files, by this way can get the all the files read by csv_files using glob.
    new_doc=pd.read_csv(csv_files_training[i],sep=';') # reading the new csv file as new doc
    main_Training=main_Training.append(new_doc, ignore_index=True) # appending the csv files making a big csv that consists of all the csv files.
main_Training


sss=[] # making a new list.
oneexample=[]
for i in range(len(main_Training.values)): # iterating 0-len(main_Training.values) that is training dataset lenght.
    if main_Training.values[i,-1] not in sss:
        oneexample.append(main_Training.values[i,:]) #appending the main_Training dataset row number i.
        sss.append(main_Training.values[i,-1]) # appending the class id of row number i
      
# Making a new pandas dataframe from oneexample list. and giving it columns names.        


One_Example=pd.DataFrame(oneexample,columns=['Filename', 'Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2', 'ClassId'])
One_Example

csv_files_training


plt.figure(figsize=[14,25]) # set image size
plt.subplots_adjust(wspace = 0.2)# set distance between the subplots

i = 0 # i is the index use for subploting the means at what number subplot will be plot. 
for i in range(len(One_Example)): # range depends on number of classes
    # we are getting the image path from csv_files name thats is dataset/Training\\00000\\GT-00000.csv
    # then spliting it at GT and we have dataset/Training\\00000\\ after that adding the name of one
    # example that we are dealing like dataset/Testing\\00001\\01983_00002.ppm
    img_path=csv_files_training[i].split('GT')[0]+One_Example['Filename'][i] 
    img = cv2.imread(img_path) # opencv use for reading image.
    # croping the image based on the coordinates given us by csv files
    crop_image=img[One_Example['Roi.Y1'][i]:One_Example['Roi.X2'][i],One_Example['Roi.X1'][i]:One_Example['Roi.Y2'][i]]
    #converting the color RGB so that we can actually view it.
    crop_image=cv2.cvtColor(crop_image,cv2.COLOR_BGR2RGB)
    plt.subplot(13,5,i+1)
    i+=1
    imgplot = plt.imshow(crop_image)
plt.show() # plot showing at the end.





for i in range(len(One_Example)): # range depends on number of classes
    # we are getting the image path from csv_files name thats is dataset/Training\\00000\\GT-00000.csv
    # then spliting it at GT and we have dataset/Training\\00000\\ after that adding the name of one
    # example that we are dealing like dataset/Testing\\00001\\01983_00002.ppm
    img_path=csv_files_training[i].split('GT')[0]+One_Example['Filename'][i] 
    img = cv2.imread(img_path) # opencv use for reading image.
    # croping the image based on the coordinates given us by csv files
    crop_image=img[One_Example['Roi.Y1'][i]:One_Example['Roi.X2'][i],One_Example['Roi.X1'][i]:One_Example['Roi.Y2'][i]]
    cv2.imwrite('classes_images/'+str(One_Example['ClassId'][i])+'.png',crop_image) # use for saving the image.


def images_to_hog(main,Images_Directory): # function defining that can be call for both test and training
    Features=[]
    Labels=[]
    for i in range(0,len(main)): #len(main)
        # we are getting the image path from csv_files name thats is dataset/Training\\00000\\GT-00000.csv
        # then spliting it at GT and we have dataset/Training\\00000\\ after that adding the name of one
        # example that we are dealing like dataset/Testing\\00001\\01983_00002.ppm
        img_path=Images_Directory+'/00000'[:-len(str(main['ClassId'][i]))]+str(main['ClassId'][i])+'/'+main['Filename'][i]
        img = cv2.imread(img_path) # opencv use for reading image.
        # croping the image based on the coordinates given us by csv files
        img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.medianBlur(img,3)
        crop_image=img[main['Roi.Y1'][i]:main['Roi.X2'][i],main['Roi.X1'][i]:main['Roi.Y2'][i]]
        crop_image=cv2.resize(crop_image, (64, 64)) #Resize the image to 64*64.
        # Apply Hog from skimage library it takes image as crop image.Number of orientation bins that gradient
        # need to calculate.
        ret,crop_image = cv2.threshold(crop_image,127,255,cv2.THRESH_BINARY)
        descriptor = hog(crop_image, orientations=8,pixels_per_cell=(4,4))
        Features.append(descriptor)#hog features saving
        Labels.append(main['ClassId'][i])#class id saving
    
    Features=np.array(Features)# converting to numpy array.
    Labels=np.array(Labels)
    return Features,Labels

Test_Images_Directory='/content/drive/MyDrive/Testing'

Features_Testing,Labels_Testing=images_to_hog(main_Testing,Test_Images_Directory) # giving values to images_to_hog function
print ('Testing HOG output Features shape : ',Features_Testing.shape)
print ('Testing HOG output Labels shape: ',Labels_Testing.shape)

csv_files_Testing=glob.glob(Test_Images_Directory+'/**/*.csv',recursive=True) # recursive true means it will check
                                                                              # folder inside the folder as well.
main_Testing=pd.read_csv(csv_files_Testing[0],sep=';') # reading first csv and assining it main csv.
# for loop iteration from 1 to number of files, by this way can get the all the files read by csv_files using glob.
for i in range(1,len(csv_files_Testing)):
    new_doc=pd.read_csv(csv_files_Testing[i],sep=';')# reading the new csv file as new doc
    # appending the csv files making a big csv that consists of all the csv files.
    main_Testing=main_Testing.append(new_doc, ignore_index=True)
main_Testing

Features_Training,Labels_Training=images_to_hog(main_Testing,Test_Images_Directory) # giving values to images_to_hog function
print ('Training HOG output Features shape : ',Features_Training.shape)
print ('Training HOG output Labels shape: ',Labels_Training.shape)

# Applying PCA
pca = PCA(n_components = 61)
X_train = pca.fit_transform(Features_Training)
X_test = pca.transform(Features_Testing)

print ('New Train Dataset shape after PCA: ',X_train.shape)
print ('New Test Dataset shape after PCA: ',X_test.shape)

print ('New Train Dataset shape after PCA: ',X_train.shape)

classifier=SVC(kernel='linear',degree = 3,gamma='auto',C=8.7) # Calling the function SVC to implement SVM
classifier.fit(X_train,Labels_Training) # Training the Classifier on Train date
                                        #labels_Trainig = y_training

print ('SVM Mean Accuracy of Training dataset: ',classifier.score(X_train,Labels_Training))
print ('SVM Mean Accuracy of Test dataset: ',classifier.score(X_test,Labels_Testing))

#prediction
from sklearn.metrics import confusion_matrix,accuracy_score,precision_score
prediction = classifier.predict(X_test)

a=accuracy_score(Labels_Training,prediction)
print("accuracy is : ",a*100)

from mlxtend.plotting import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Labels_Testing,prediction)
plot_confusion_matrix(conf_mat = cm,figsize=(5,5),
                     show_normed = True)